{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "updated_mask_type.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Pr6m7EidEX",
        "outputId": "5c0e01fd-0b32-4cca-b199-1b4dfc7731fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.test.gpu_device_name() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQhQzxG-tk2D",
        "outputId": "e5a9bf3d-b349-4bfb-d544-02af96a4ae02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJo3xfFEtuqj",
        "outputId": "68bed2c0-5fc9-444d-ee57-35df9db8729c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/mask_type_class\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mask_type_class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3FEUU1iuA9O"
      },
      "source": [
        "#!unzip type_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkoIWuVxhYap"
      },
      "source": [
        "import os,shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TthY2rvfhYaw"
      },
      "source": [
        "from skimage.io import imread, imshow, imsave"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8mJ5kckhYa0"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqAx82c6hYa8"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SreVMUFhYa8"
      },
      "source": [
        "path_to_annotations = '/Users/shruthiravi/Documents/rsi_20/mask_data/annotations/'\n",
        "list_of_annotations = os.listdir(path = path_to_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y1kl78VhYbA"
      },
      "source": [
        "correct_files = []\n",
        "for number in list_of_annotations:\n",
        "    if '.json' in number:\n",
        "        correct_files.append(number)\n",
        "    else:\n",
        "        print(number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEKrXyBJhYbD"
      },
      "source": [
        "all_annotations = {}\n",
        "for fname in correct_files:\n",
        "    # open file     \n",
        "    with open(os.path.join(path_to_annotations, fname)) as f:\n",
        "        # load file & get into dict\n",
        "        data = json.load(f)    \n",
        "    # extract value of the FileName key\n",
        "    fileNameKey = data['FileName']\n",
        "    # initialize empty list\n",
        "    annotations_list = []\n",
        "    # for each element in annotations\n",
        "    for element in data['Annotations']:\n",
        "        # extract bounding_box\n",
        "        bounding_box = element['BoundingBox']\n",
        "        # extract class_name\n",
        "        class_name = element['classname']\n",
        "        # put them into a tuple \n",
        "        final_annotation = (bounding_box, class_name)\n",
        "        # put the tuple into list\n",
        "        annotations_list.append(final_annotation)\n",
        "    # list becomes value of key\n",
        "    all_annotations[fileNameKey] = annotations_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGm6tEhhYbY"
      },
      "source": [
        "print(all_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozAsVHThYbc"
      },
      "source": [
        "classes = []\n",
        "for key in all_annotations:\n",
        "    for element in all_annotations[key]:\n",
        "        classes.append(element[1])\n",
        "set_of_classes = set(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43eTiuDLhYbl"
      },
      "source": [
        "set([e[1] for k in all_annotations.keys() for e in all_annotations[k] ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwWuyIlJhYbo"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FShk_CvhYbt"
      },
      "source": [
        "Counter(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXdsKg34hYbv"
      },
      "source": [
        "base_dir = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imABXEe1hYby"
      },
      "source": [
        "splits = [x for x in os.listdir(base_dir) if x != '.DS_Store']\n",
        "splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2AhK-TJhYb9"
      },
      "source": [
        "folds = ['train', 'test', 'valid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zTt0hTzhYcC"
      },
      "source": [
        "mask_types = ['mask_surgical','scarf_bandana', 'mask_colorful','face_shield']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f643U5qPhYcF"
      },
      "source": [
        "for fold in folds:\n",
        "     os.mkdir(os.path.join(base_dir, fold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXXOd7AfhYcH"
      },
      "source": [
        "for fold in folds:\n",
        "    for folder in mask_types:\n",
        "        splits_dir = os.path.join(base_dir, fold)\n",
        "        os.mkdir(os.path.join(splits_dir, folder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OevJr9KdhYcJ"
      },
      "source": [
        "def save_photos(tuple_of_info, path_to_save, occurence, img_path='/Users/shruthiravi/Documents/rsi_20/mask_data/images'):\n",
        "    '''this function takes in a tuple'''\n",
        "    name, label, bb = tuple_of_info\n",
        "    final_path = os.path.join(path_to_save, label)\n",
        "    image = imread(os.path.join(img_path, name))\n",
        "    [tl_x, tl_y, br_x, br_y] = bb\n",
        "    cropped = image[tl_y:br_y, tl_x:br_x, :] \n",
        "    name_pieces = name.split('.')\n",
        "    new_name = name_pieces[0] + f\"_{occurence}.\" + name_pieces[1]\n",
        "    further_path = os.path.join(path_to_save, label)\n",
        "    imsave(os.path.join(further_path, new_name), cropped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ1cK1XRhYca"
      },
      "source": [
        "#current_img_name = ''\n",
        "needed_labels = ['face_with_mask', 'face_other_covering','face_with_mask_incorrect']\n",
        "mask_labels = ['mask_surgical','scarf_bandana', 'mask_colorful','face_shield']\n",
        "cropped_annotations = [] # list of three-tuples, each containing (img_name, label, bb)\n",
        "#test = []\n",
        "#train = []\n",
        "#valid = []\n",
        "# for annotation in annotations_list\n",
        "for current_img_name in all_annotations.keys():\n",
        "    for i, annotation in enumerate(all_annotations[current_img_name]):\n",
        "        # extract bounding box\n",
        "        bb = annotation[0]\n",
        "        # crop to bounding box\n",
        "        # extract classname\n",
        "        label = annotation[1]\n",
        "        # crop to bounding box    \n",
        "        if label in needed_labels: \n",
        "            [tl_x, tl_y, br_x, br_y] = bb\n",
        "            if (br_x-tl_x) > 0 and (br_y-tl_y) >0:\n",
        "                for val_label in all_annotations[current_img_name][i+1:]:\n",
        "                    mask_type = val_label[1]\n",
        "                    if mask_type in mask_labels:\n",
        "                        specific_bb = val_label[0]\n",
        "                        [tl_c_x, tl_c_y,br_c_x,br_c_y] = specific_bb\n",
        "                        if tl_c_x > tl_x & tl_c_y > tl_y & br_c_x < br_x & br_c_y < br_y:\n",
        "                            fixed = (current_img_name, mask_type, bb)\n",
        "                            cropped_annotations.append(fixed) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raeuPKH9hYcf"
      },
      "source": [
        "#save_photos(train[1301],'/Users/shruthiravi/Documents/rsi_20/mask_type_classification/train', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOsQ5yQFhYcs"
      },
      "source": [
        "# randomly shuffle the list \n",
        "random.shuffle(cropped_annotations)\n",
        "# determine which split\n",
        "total_size = len(cropped_annotations)\n",
        "perc_train = 0.7\n",
        "perc_test = 0.15\n",
        "perc_valid = 0.15\n",
        "\n",
        "train = cropped_annotations[0:int(perc_train*total_size)]\n",
        "test = cropped_annotations[int(perc_train*total_size):int((perc_train+perc_test)*total_size)]\n",
        "valid = cropped_annotations[int((perc_train+perc_test)*total_size):]\n",
        "fold_dict = {'train': train, 'test': test, 'valid': valid}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZEStAvthYcv"
      },
      "source": [
        "Counter([b[1] for b in train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "falRa6Z0hYcx"
      },
      "source": [
        "dest_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/'\n",
        "# train_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/train'\n",
        "# test_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/test'\n",
        "# valid_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/valid'\n",
        "num_occ = {}\n",
        "\n",
        "for fold in fold_dict:\n",
        "    for example in fold_dict[fold]:\n",
        "        if example[0] in num_occ:\n",
        "            num_occ[example[0]] += 1\n",
        "        else:\n",
        "            num_occ[example[0]] = 0\n",
        "        save_photos(example, os.path.join(dest_path, fold), num_occ[example[0]])\n",
        "        print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUKSdB4YhYcz"
      },
      "source": [
        "def print_img(fname):\n",
        "    test_image = imread('/Users/shruthiravi/Documents/rsi_20/mask_data/images/%s' % fname)\n",
        "    test_annotations = all_annotations[fname]\n",
        "    y, x, c = test_image.shape\n",
        "    colors = ['red', 'green', 'blue', 'pink', 'black']\n",
        "    for i, ann in enumerate(test_annotations):\n",
        "        [tl_x, tl_y, br_x, br_y] = ann[0]\n",
        "        color = colors[i%len(colors)]\n",
        "        plt.plot(range(tl_x, br_x),[tl_y for _ in range(tl_x, br_x)],  c=color, label = ann[1])\n",
        "        plt.plot([tl_x for _ in range(tl_y, br_y)],range(tl_y, br_y),  c=color)\n",
        "        plt.plot(range(tl_x, br_x), [br_y for _ in range(tl_x, br_x)], c=color)\n",
        "        plt.plot([br_x for _ in range(tl_y, br_y)], range(tl_y, br_y), c=color)\n",
        "        #plt.legend()\n",
        "        imshow(test_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T_7n1cnu4ns",
        "outputId": "62205ba8-7949-4f57-9ed8-aab141626552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls {train_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My': No such file or directory\n",
            "ls: cannot access 'Drive/mask_type_class/updated/train/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8nmSDggwusT",
        "outputId": "679eefd4-6697-49f6-c113-fe582f04454c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls {test_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mask_colorful  mask_surgical  respirator  scarf_bandana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_KGdIipwx1l",
        "outputId": "6125f787-84b6-4e7a-b3bb-a6363055d29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls {val_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cloth  respirator  scarf_bandana  surgical\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMWLPS1jhYdQ"
      },
      "source": [
        "# Actual Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zfzbeJvuVac"
      },
      "source": [
        "base_path = r\"\"\"/content/drive/My Drive/mask_type_class/updated/\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdY_hT9DhYdE"
      },
      "source": [
        "train_dir = base_path + \"train/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2PfPnR7hYdI"
      },
      "source": [
        "test_dir = base_path + \"test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJDqs2FmhYdO"
      },
      "source": [
        "val_dir = base_path + \"valid/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x21Ng8bqhYdR",
        "outputId": "e1e70356-2517-4fa3-d2d4-698a1f228083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gb9Z24hYdT"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzEwXCOMhYdV",
        "outputId": "a111bf75-ad82-4ff8-f174-9034dc301418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4100 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2eF16P0hYd1",
        "outputId": "6d6f0201-4197-453d-da9c-c45d5e8241b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 897 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FQjGsPyhYd8",
        "outputId": "d753b69f-92cd-47e4-ad38-126d6eab8309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (20, 224, 224, 3)\n",
            "labels batch shape: (20, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NO0686UhYeC"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mxoHR8ZhYeC"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n",
        "                       input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(4,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M0eF0fKhYeF",
        "outputId": "4fae7b75-01ba-48ef-b1ae-d05ed3433d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,454,660\n",
            "Trainable params: 3,454,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNl4CmerhYeH"
      },
      "source": [
        "# Compile "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhyR4RwNhYeI"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbKdHrpahYeZ"
      },
      "source": [
        "# Fit using Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQIEmqLDhYeZ",
        "outputId": "c8c1d161-6abb-4598-8a9f-bd59d8c6d09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=40,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.8988 - acc: 0.6785 - val_loss: 0.5427 - val_acc: 0.7525\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.8195 - acc: 0.7320 - val_loss: 0.7805 - val_acc: 0.7550\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.7518 - acc: 0.7515 - val_loss: 0.7136 - val_acc: 0.7431\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.7530 - acc: 0.7465 - val_loss: 0.6623 - val_acc: 0.7475\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.7120 - acc: 0.7540 - val_loss: 1.0393 - val_acc: 0.7632\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.6746 - acc: 0.7735 - val_loss: 0.6285 - val_acc: 0.7800\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.7104 - acc: 0.7525 - val_loss: 0.6337 - val_acc: 0.7809\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.6260 - acc: 0.7925 - val_loss: 0.3381 - val_acc: 0.7925\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6242 - acc: 0.7805 - val_loss: 0.8074 - val_acc: 0.7683\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.6602 - acc: 0.7720 - val_loss: 0.9198 - val_acc: 0.7650\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.6350 - acc: 0.7660 - val_loss: 0.6159 - val_acc: 0.7700\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.5744 - acc: 0.7975 - val_loss: 0.7333 - val_acc: 0.7758\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.5700 - acc: 0.7965 - val_loss: 0.7774 - val_acc: 0.8000\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.5571 - acc: 0.8035 - val_loss: 0.4894 - val_acc: 0.7884\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.5272 - acc: 0.8125 - val_loss: 0.3913 - val_acc: 0.7750\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.5415 - acc: 0.8065 - val_loss: 0.4729 - val_acc: 0.8212\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.4938 - acc: 0.8310 - val_loss: 0.9429 - val_acc: 0.7500\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.4894 - acc: 0.8245 - val_loss: 0.5954 - val_acc: 0.7708\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4524 - acc: 0.8465 - val_loss: 0.6621 - val_acc: 0.8000\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.4617 - acc: 0.8395 - val_loss: 1.4162 - val_acc: 0.7875\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.4268 - acc: 0.8455 - val_loss: 0.5044 - val_acc: 0.7557\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.4091 - acc: 0.8560 - val_loss: 0.4509 - val_acc: 0.7850\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.3987 - acc: 0.8635 - val_loss: 0.3816 - val_acc: 0.8489\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.3904 - acc: 0.8565 - val_loss: 0.6436 - val_acc: 0.7625\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3597 - acc: 0.8815 - val_loss: 1.2614 - val_acc: 0.8060\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3287 - acc: 0.8815 - val_loss: 1.2408 - val_acc: 0.7925\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3494 - acc: 0.8805 - val_loss: 0.2034 - val_acc: 0.7935\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2999 - acc: 0.8975 - val_loss: 1.1137 - val_acc: 0.7875\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2807 - acc: 0.9085 - val_loss: 0.5697 - val_acc: 0.8125\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.2776 - acc: 0.8980 - val_loss: 1.9877 - val_acc: 0.7909\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.2644 - acc: 0.9110 - val_loss: 0.7120 - val_acc: 0.8050\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2446 - acc: 0.9175 - val_loss: 1.0124 - val_acc: 0.7809\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2377 - acc: 0.9190 - val_loss: 0.4249 - val_acc: 0.8200\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.2168 - acc: 0.9365 - val_loss: 0.7233 - val_acc: 0.7809\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.2044 - acc: 0.9350 - val_loss: 0.6812 - val_acc: 0.7300\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.1735 - acc: 0.9415 - val_loss: 0.4194 - val_acc: 0.7531\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.1999 - acc: 0.9395 - val_loss: 0.9559 - val_acc: 0.7800\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.1559 - acc: 0.9470 - val_loss: 0.5505 - val_acc: 0.8100\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.1839 - acc: 0.9375 - val_loss: 0.8234 - val_acc: 0.7632\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.1471 - acc: 0.9495 - val_loss: 0.9066 - val_acc: 0.7850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uZ0LjSThYed"
      },
      "source": [
        "# Save The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoZm2ZkGhYee",
        "outputId": "4579d819-5993-4c2f-8e1d-78115f80972c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save(\"updated_types_colab.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRDg8cwihYeg"
      },
      "source": [
        "# Test it Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX6v3LXdhYeg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "model = load_model('my_model_1.h5')\n",
        "\n",
        "# Load model\n",
        "#model = load_model('model.json')\n",
        "\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "#test_generator = test_datagen.flow_from_directory(\n",
        "#        test_dir,\n",
        "#        target_size=(150, 150),\n",
        "#        batch_size=20,\n",
        "#        class_mode='categorical',\n",
        "#        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uaGWX-6hYeo"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=test_dir,\n",
        "    target_size=(28, 28),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqZI7UtnhYep"
      },
      "source": [
        "test_generator.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUl6nrhNhYez"
      },
      "source": [
        "pred=cnn.predict_generator(test_generator,verbose=1,steps=306/batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHwlfEPchYe4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4gN3AVWhYe-"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YTP4LwdhYe-"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9GIxmW7hYfE"
      },
      "source": [
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xKC9iZThYfG"
      },
      "source": [
        "train_face_shield_dir = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/train/face_shield/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0oOdiwfhYfI"
      },
      "source": [
        "fnames = [os.path.join(train_face_shield_dir, fname) for\n",
        "         fname in os.listdir(train_face_shield_dir)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqeZsZJwhYfK"
      },
      "source": [
        "img_path = fnames[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGNg4HN6hYfQ"
      },
      "source": [
        "img = image.load_img(img_path, target_size=(150,150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AZlEFH0hYfc"
      },
      "source": [
        "x = image.img_to_array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEx0jyAkhYfn"
      },
      "source": [
        "x = x.reshape((1,) + x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxWZ25MQhYf3"
      },
      "source": [
        "i = 0\n",
        "for batch in datagen.flow(x,batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0 :\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYP51E4hYgM"
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4qnJZu0hYgO"
      },
      "source": [
        "# Adding Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIf0YnbLhYgO"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n",
        "                       input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv_5Aq1ghYgS"
      },
      "source": [
        "train_datagen = ImageDataGenerator (\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=-.2,\n",
        "    horizontal_flip=True,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_0BjU4shYgT"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_RKFm8qhYgV",
        "outputId": "34fd6d64-9edf-4199-ec35-6cb69979ee69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4100 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AsVyMlvhYgY",
        "outputId": "a1d445d1-e435-49d9-b2ee-2502b2be72bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 897 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKv5ai2HPnb9",
        "outputId": "457bf173-9ea1-49c7-8b45-1bd5265c8ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,454,660\n",
            "Trainable params: 3,454,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CKOBPz7hYga",
        "outputId": "ae343634-bb2a-4639-a615-d83a918b5f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=40,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.9408 - acc: 0.6575 - val_loss: 0.9655 - val_acc: 0.7150\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.8634 - acc: 0.6885 - val_loss: 0.8638 - val_acc: 0.7270\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.8094 - acc: 0.7110 - val_loss: 0.4737 - val_acc: 0.7839\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.8292 - acc: 0.7055 - val_loss: 0.9014 - val_acc: 0.7483\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.7930 - acc: 0.7150 - val_loss: 1.3334 - val_acc: 0.7722\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.7666 - acc: 0.7405 - val_loss: 0.8683 - val_acc: 0.7789\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.7838 - acc: 0.7270 - val_loss: 0.6976 - val_acc: 0.7617\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.7371 - acc: 0.7455 - val_loss: 0.7595 - val_acc: 0.7169\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.7465 - acc: 0.7405 - val_loss: 0.6664 - val_acc: 0.7789\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.7533 - acc: 0.7320 - val_loss: 0.8423 - val_acc: 0.7583\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.7480 - acc: 0.7370 - val_loss: 0.5536 - val_acc: 0.7772\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.7243 - acc: 0.7460 - val_loss: 0.2866 - val_acc: 0.7873\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.7187 - acc: 0.7510 - val_loss: 0.6486 - val_acc: 0.7800\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.7280 - acc: 0.7445 - val_loss: 0.8320 - val_acc: 0.7772\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.6973 - acc: 0.7630 - val_loss: 0.5365 - val_acc: 0.7722\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.7103 - acc: 0.7440 - val_loss: 0.5667 - val_acc: 0.7900\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.7326 - acc: 0.7410 - val_loss: 0.5021 - val_acc: 0.7940\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.6731 - acc: 0.7690 - val_loss: 0.7401 - val_acc: 0.7789\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.7021 - acc: 0.7575 - val_loss: 0.6813 - val_acc: 0.7667\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.7010 - acc: 0.7535 - val_loss: 0.7295 - val_acc: 0.7839\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.6927 - acc: 0.7515 - val_loss: 0.5157 - val_acc: 0.7655\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.6869 - acc: 0.7590 - val_loss: 0.5931 - val_acc: 0.7517\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.6671 - acc: 0.7650 - val_loss: 0.3225 - val_acc: 0.7973\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.7150 - acc: 0.7445 - val_loss: 0.8919 - val_acc: 0.7973\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.6321 - acc: 0.7780 - val_loss: 0.2454 - val_acc: 0.7833\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.6900 - acc: 0.7515 - val_loss: 0.4710 - val_acc: 0.7889\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.6716 - acc: 0.7575 - val_loss: 0.4721 - val_acc: 0.7990\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.6716 - acc: 0.7620 - val_loss: 0.2143 - val_acc: 0.7900\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.6547 - acc: 0.7710 - val_loss: 0.6588 - val_acc: 0.7822\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.6526 - acc: 0.7645 - val_loss: 0.5433 - val_acc: 0.7471\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.6510 - acc: 0.7695 - val_loss: 0.2886 - val_acc: 0.8017\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.6916 - acc: 0.7495 - val_loss: 0.9497 - val_acc: 0.7856\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.6392 - acc: 0.7780 - val_loss: 0.7984 - val_acc: 0.8124\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.6443 - acc: 0.7750 - val_loss: 0.9262 - val_acc: 0.8167\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.6526 - acc: 0.7755 - val_loss: 0.3945 - val_acc: 0.7638\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.6359 - acc: 0.7700 - val_loss: 0.5154 - val_acc: 0.8023\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.6643 - acc: 0.7675 - val_loss: 0.3637 - val_acc: 0.8067\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.6245 - acc: 0.7790 - val_loss: 0.6301 - val_acc: 0.7940\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.6619 - acc: 0.7600 - val_loss: 0.6264 - val_acc: 0.7990\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 24s 237ms/step - loss: 0.6601 - acc: 0.7640 - val_loss: 0.7811 - val_acc: 0.7867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPFkxY0hYgd",
        "outputId": "b3340081-08cc-495e-dc40-26ccf0630719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"dropout_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save(\"updated_types_dropout_7_20.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3RbeW9hYgf"
      },
      "source": [
        "# NEW DATA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlL3WnsbhYgg"
      },
      "source": [
        "train_dir = '/Users/shruthiravi/Documents/rsi_20/combined/train/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyGwFpd5hYgh"
      },
      "source": [
        "test_dir = '/Users/shruthiravi/Documents/rsi_20/combined/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvqQs0kkhYgk"
      },
      "source": [
        "val_dir = '/Users/shruthiravi/Documents/rsi_20/combined/valid/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWGyN0dmhYgn"
      },
      "source": [
        "# Actual Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyT2axkFhYgq"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNsCtByOhYhA"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb4_dlIahYhB",
        "outputId": "3f72ed12-dba8-4eaa-c51f-d09fab966fd3"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4100 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejgNZDhhYhD",
        "outputId": "6741a3cc-100d-49d3-8561-df2de136b17d"
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 897 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhmbFYamhYhG"
      },
      "source": [
        "i = 0\n",
        "for batch in validation_generator.:\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0 :\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci1jmpSihYhS",
        "outputId": "a3f0f0c5-8264-46b6-e33d-da61a4effad6"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (20, 150, 150, 3)\n",
            "labels batch shape: (20, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecN3hdB-hYhY"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC048AudhYhY",
        "outputId": "4dbfcf9b-4aa2-43d1-b4e1-3b5e2109d13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n",
        "                       input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(4,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d06f01ef007c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n\u001b[0;32m----> 6\u001b[0;31m                        input_shape=(150,150,3)))\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             self.bias = self.add_weight(shape=(self.filters,),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         weight = K.variable(initializer(shape, dtype=dtype),\n\u001b[0m\u001b[1;32m    280\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             x = K.random_uniform(shape, -limit, limit,\n\u001b[0;32m--> 227\u001b[0;31m                                  dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   4355\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         return tf_keras_backend.random_uniform(\n\u001b[0;32m-> 4357\u001b[0;31m             shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   5684\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5685\u001b[0m   return random_ops.random_uniform(\n\u001b[0;32m-> 5686\u001b[0;31m       shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   5687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;31m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;31m# not convertible to Tensors because of mixed content.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m           pywrap_tfe.TFE_ContextOptionsSetLazyRemoteInputsCopy(\n\u001b[1;32m    514\u001b[0m               opts, self._lazy_remote_inputs_copy)\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsw1Bqm5hYha",
        "outputId": "d8ff0afb-f7ad-499f-8e9c-9e3044cfe4ac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,454,660\n",
            "Trainable params: 3,454,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRKk3x9WhYhb"
      },
      "source": [
        "# Compile "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH1M3fsLhYhc"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-FnS6FihYhd",
        "outputId": "2b7d3aad-3212-48fe-dd9f-c39462101a5d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,454,660\n",
            "Trainable params: 3,454,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYZTj2t4hYhj"
      },
      "source": [
        "# Fit using Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4n2LWznhYhk",
        "outputId": "09c71ce9-d24e-4f6e-fd2e-146f5effee69"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochst=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-f0160fe33617>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 52s 522ms/step - loss: 0.3875 - acc: 0.6795 - val_loss: 0.3189 - val_acc: 0.7700\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 54s 543ms/step - loss: 0.3427 - acc: 0.7400 - val_loss: 0.3323 - val_acc: 0.7550\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.3359 - acc: 0.7455 - val_loss: 0.3179 - val_acc: 0.7500\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 51s 508ms/step - loss: 0.3251 - acc: 0.7535 - val_loss: 0.3111 - val_acc: 0.7700\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 51s 510ms/step - loss: 0.3097 - acc: 0.7530 - val_loss: 0.2868 - val_acc: 0.7850\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.2990 - acc: 0.7710 - val_loss: 0.3039 - val_acc: 0.7700\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 0.3067 - acc: 0.7490 - val_loss: 0.3534 - val_acc: 0.7100\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 51s 509ms/step - loss: 0.2959 - acc: 0.7615 - val_loss: 0.2839 - val_acc: 0.7850\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 52s 519ms/step - loss: 0.2769 - acc: 0.7750 - val_loss: 0.2733 - val_acc: 0.7925\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.2735 - acc: 0.7905 - val_loss: 0.2850 - val_acc: 0.7750\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 52s 517ms/step - loss: 0.2761 - acc: 0.7765 - val_loss: 0.2845 - val_acc: 0.7850\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 0.2666 - acc: 0.7900 - val_loss: 0.2796 - val_acc: 0.7925\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 55s 555ms/step - loss: 0.2590 - acc: 0.7925 - val_loss: 0.2501 - val_acc: 0.8150\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 419s 4s/step - loss: 0.2381 - acc: 0.8120 - val_loss: 0.2915 - val_acc: 0.7650\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 63s 632ms/step - loss: 0.2457 - acc: 0.8100 - val_loss: 0.2806 - val_acc: 0.7925\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 0.2314 - acc: 0.8185 - val_loss: 0.2621 - val_acc: 0.8050\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 50s 505ms/step - loss: 0.2289 - acc: 0.8220 - val_loss: 0.2537 - val_acc: 0.8250\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 51s 512ms/step - loss: 0.2153 - acc: 0.8350 - val_loss: 0.2520 - val_acc: 0.8125\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 207s 2s/step - loss: 0.2133 - acc: 0.8370 - val_loss: 0.2837 - val_acc: 0.7900\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 54s 543ms/step - loss: 0.2117 - acc: 0.8375 - val_loss: 0.2640 - val_acc: 0.7975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JKz14YthYhl"
      },
      "source": [
        "# Load the Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztZOKqcDhYhm"
      },
      "source": [
        "# example of loading the resnet50 model\n",
        "from keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHUOxe7j0RgY"
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HadXUblf0iQl"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53QeemGnzKcJ",
        "outputId": "4a3d7d90-ad7c-496a-c4cd-1deccd8a745b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "help(ResNet50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function wrapper in module keras.applications:\n",
            "\n",
            "wrapper(*args, **kwargs)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCp6YocThYho",
        "outputId": "46fa1d2f-df73-4b68-afb1-3b06cb3766ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# load model\n",
        "resnet_model = ResNet50(\n",
        "                classes = 4,\n",
        "                pooling = 'max',\n",
        "                weights = 'imagenet',\n",
        "                include_top = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebnfNaHIz7Nr"
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = resnet_model.output\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(4, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s3ax46uhYhq",
        "outputId": "48ef077a-bb7e-41a4-a6fd-20439aa97808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# summarize the model\n",
        "resnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 2048)         0           activation_49[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a6NkDlQmxJ5"
      },
      "source": [
        "weighted_model = Model(inputs=resnet_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMLuiNYXs0Ga",
        "outputId": "d20e15b3-fda2-4c9c-b9d1-56b1cd3fa8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "weighted_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          1049088     global_max_pooling2d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            2052        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,638,852\n",
            "Trainable params: 24,585,732\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpAZTwMohYht"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "weighted_model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YlXJaFjxz-9"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint('best_weighted_multi_model_3.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giDXvzC9hYic",
        "outputId": "919fd0e7-82f2-4d8d-a7e5-918999c302e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = weighted_model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=1000,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=40,\n",
        "    callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 0.0855 - acc: 0.9695 - val_loss: 31.1663 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.81500, saving model to best_weighted_multi_model_3.h5\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0782 - acc: 0.9780 - val_loss: 9.4459 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.81500 to 0.82309, saving model to best_weighted_multi_model_3.h5\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 0.0800 - acc: 0.9790 - val_loss: 0.2340 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.82309\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.1016 - acc: 0.9700 - val_loss: 2.3237 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.82309\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.2386 - acc: 0.9650 - val_loss: 0.7562 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.82309\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0590 - acc: 0.9790 - val_loss: 5.3764 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.82309 to 0.84818, saving model to best_weighted_multi_model_3.h5\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0634 - acc: 0.9765 - val_loss: 2.7011 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.84818\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0926 - acc: 0.9720 - val_loss: 0.0209 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.84818\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0701 - acc: 0.9730 - val_loss: 4.9117 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.84818\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0918 - acc: 0.9690 - val_loss: 0.0754 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.84818\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0546 - acc: 0.9805 - val_loss: 5.3602 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.84818\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.1113 - acc: 0.9655 - val_loss: 6.6261 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.84818\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0609 - acc: 0.9755 - val_loss: 2.6155 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.84818\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0798 - acc: 0.9720 - val_loss: 5.2276 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.84818\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.1186 - acc: 0.9770 - val_loss: 4.2576 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.84818\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.2307 - acc: 0.9675 - val_loss: 4.9016 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.84818\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.0664 - acc: 0.9815 - val_loss: 4.6689 - val_acc: 0.8269\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.84818\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 0.0797 - acc: 0.9750 - val_loss: 4.0450 - val_acc: 0.8181\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.84818\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.5044 - acc: 0.9650 - val_loss: 8.7169 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.84818\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.2222 - acc: 0.9740 - val_loss: 0.0056 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.84818\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0726 - acc: 0.9775 - val_loss: 2.2474 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.84818 to 0.84944, saving model to best_weighted_multi_model_3.h5\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0662 - acc: 0.9745 - val_loss: 2.5758 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.84944\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0830 - acc: 0.9835 - val_loss: 1.5177 - val_acc: 0.7980\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.84944\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.2959 - acc: 0.9730 - val_loss: 1.5044 - val_acc: 0.8394\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.84944\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.0604 - acc: 0.9770 - val_loss: 6.9367 - val_acc: 0.8206\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.84944\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0848 - acc: 0.9680 - val_loss: 7.9997 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.84944\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.1074 - acc: 0.9785 - val_loss: 6.3887 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.84944\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0756 - acc: 0.9740 - val_loss: 2.5489 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.84944\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0583 - acc: 0.9785 - val_loss: 0.1316 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.84944\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0824 - acc: 0.9720 - val_loss: 0.9744 - val_acc: 0.8469\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.84944\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0472 - acc: 0.9795 - val_loss: 0.0146 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.84944\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0568 - acc: 0.9775 - val_loss: 4.7244 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.84944\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0606 - acc: 0.9725 - val_loss: 0.7850 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84944\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0619 - acc: 0.9760 - val_loss: 27.3193 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.84944\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.1094 - acc: 0.9750 - val_loss: 0.7532 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.84944\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0379 - acc: 0.9815 - val_loss: 5.6570 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.84944\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0977 - acc: 0.9730 - val_loss: 1.3647 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.84944\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0593 - acc: 0.9755 - val_loss: 6.5360 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.84944\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.1024 - acc: 0.9705 - val_loss: 1.8252 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.84944\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0430 - acc: 0.9810 - val_loss: 2.9160 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.84944\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0870 - acc: 0.9760 - val_loss: 4.1580 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.84944\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0496 - acc: 0.9770 - val_loss: 4.9771 - val_acc: 0.8469\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.84944\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0762 - acc: 0.9760 - val_loss: 17.2939 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.84944\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.4959 - acc: 0.9785 - val_loss: 2.6395 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.84944\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0899 - acc: 0.9740 - val_loss: 3.6489 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.84944\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0444 - acc: 0.9780 - val_loss: 0.0424 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.84944\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.1842 - acc: 0.9790 - val_loss: 2.1654 - val_acc: 0.8269\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.84944\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0749 - acc: 0.9775 - val_loss: 4.1362 - val_acc: 0.8407\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.84944\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0616 - acc: 0.9780 - val_loss: 3.2761 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.84944\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0791 - acc: 0.9795 - val_loss: 3.3793 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.84944\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0798 - acc: 0.9755 - val_loss: 5.6147 - val_acc: 0.8118\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.84944\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.1445 - acc: 0.9805 - val_loss: 6.0266 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.84944\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0382 - acc: 0.9765 - val_loss: 2.2063 - val_acc: 0.8319\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.84944\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0636 - acc: 0.9775 - val_loss: 0.5518 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.84944\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0546 - acc: 0.9780 - val_loss: 3.7811 - val_acc: 0.8062\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.84944\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0665 - acc: 0.9775 - val_loss: 7.2178 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.84944\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0546 - acc: 0.9770 - val_loss: 27.7927 - val_acc: 0.8243\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.84944\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0384 - acc: 0.9820 - val_loss: 5.1684 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.84944\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0737 - acc: 0.9750 - val_loss: 9.5347 - val_acc: 0.8407\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.84944\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.0463 - acc: 0.9810 - val_loss: 4.0117 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.84944\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0490 - acc: 0.9770 - val_loss: 37.0647 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.84944\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0668 - acc: 0.9770 - val_loss: 2.0679 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.84944\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0350 - acc: 0.9810 - val_loss: 2.2404 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.84944\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.0470 - acc: 0.9765 - val_loss: 3.7760 - val_acc: 0.8213\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.84944\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0449 - acc: 0.9790 - val_loss: 6.3588 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.84944\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0581 - acc: 0.9795 - val_loss: 22.8247 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.84944\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0514 - acc: 0.9775 - val_loss: 1.4458 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.84944\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0434 - acc: 0.9795 - val_loss: 9.5859 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.84944\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0430 - acc: 0.9810 - val_loss: 6.4594 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.84944\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0655 - acc: 0.9780 - val_loss: 3.8471 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.84944\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0686 - acc: 0.9830 - val_loss: 3.6816 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.84944\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0670 - acc: 0.9765 - val_loss: 10.8053 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.84944\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0477 - acc: 0.9820 - val_loss: 0.6039 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.84944\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.0471 - acc: 0.9785 - val_loss: 6.7220 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.84944\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0585 - acc: 0.9825 - val_loss: 1.4277 - val_acc: 0.8168\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.84944\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.1566 - acc: 0.9770 - val_loss: 1.2985 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.84944\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.5730 - acc: 0.9835 - val_loss: 13.3736 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.84944\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0780 - acc: 0.9740 - val_loss: 0.3659 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.84944\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0645 - acc: 0.9725 - val_loss: 5.9492 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.84944\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0858 - acc: 0.9795 - val_loss: 1.6038 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.84944\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.0435 - acc: 0.9835 - val_loss: 4.5498 - val_acc: 0.8243\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.84944\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0392 - acc: 0.9820 - val_loss: 0.0910 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.84944\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 0.0562 - acc: 0.9790 - val_loss: 3.0408 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.84944\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 0.0411 - acc: 0.9820 - val_loss: 6.1082 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.84944\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 0.0425 - acc: 0.9825 - val_loss: 3.6562 - val_acc: 0.8256\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.84944\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 0.1212 - acc: 0.9735 - val_loss: 9.4865 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.84944\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 0.0717 - acc: 0.9780 - val_loss: 6.1331 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.84944\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 0.0474 - acc: 0.9795 - val_loss: 2.8092 - val_acc: 0.8319\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.84944\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0355 - acc: 0.9870 - val_loss: 7.6860 - val_acc: 0.8269\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.84944\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0564 - acc: 0.9745 - val_loss: 3.3844 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.84944\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0753 - acc: 0.9845 - val_loss: 2.9007 - val_acc: 0.8388\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.84944\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0392 - acc: 0.9775 - val_loss: 1.1115 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.84944\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.1268 - acc: 0.9775 - val_loss: 2.3245 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.84944\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 0.0416 - acc: 0.9795 - val_loss: 0.7262 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.84944\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.0830 - acc: 0.9775 - val_loss: 0.2011 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.84944\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 0.0782 - acc: 0.9810 - val_loss: 2.2712 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.84944\n",
            "Epoch 97/1000\n",
            " 95/100 [===========================>..] - ETA: 2s - loss: 0.0577 - acc: 0.9795"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDwmyibdXWi7",
        "outputId": "832e6b5b-9871-49be-9c5b-1ef0b9bd3c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "weighted_model_json = weighted_model.to_json()\n",
        "with open(\"weighted_model.json\", \"w\") as json_file:\n",
        "    json_file.write(weighted_model_json)\n",
        "# serialize weights to HDF5\n",
        "weighted_model.save(\"resnet_weighted_1.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnqHNj3imYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODIPjpnFHKb"
      },
      "source": [
        "# VGG19\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldq-20nhFLGq"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma2qDvIvFLGv"
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW-XQUHFFLGy"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVpzWOmWFLG3",
        "outputId": "9f95ab6a-775b-40bb-bc3d-32ba138bbe8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# load model\n",
        "vgg_model = VGG16()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 43s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KCGewJqFLG5"
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = vgg_model.output\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(4, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTkB8XaCFLG-",
        "outputId": "e8c7632c-0c7e-4f02-b293-fb972df5ce41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# summarize the model\n",
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQp-skVFLHA"
      },
      "source": [
        "wvgg_model = Model(inputs=vgg_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXXjDyM0FLHC",
        "outputId": "8d79f110-be57-4f5b-ea25-18bdf84932c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wvgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               512512    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 138,872,108\n",
            "Trainable params: 138,872,108\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_0erPq8FLHE"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "wvgg_model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPAueRSOFLHG"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint('best_weighted_vgg_multi_model_3.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yJNHAQNFLHI",
        "outputId": "2870c8f3-2ea0-4175-e3d6-c418f6469903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = wvgg_model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=1000,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=40,\n",
        "    callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 1916s 19s/step - loss: 1.2613 - acc: 0.6315 - val_loss: 1.2201 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.66250, saving model to best_weighted_vgg_multi_model_3.h5\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1190s 12s/step - loss: 1.1385 - acc: 0.6300 - val_loss: 1.2425 - val_acc: 0.6725\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.66250 to 0.67252, saving model to best_weighted_vgg_multi_model_3.h5\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 141s 1s/step - loss: 1.0248 - acc: 0.6500 - val_loss: 1.2019 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67252\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 1.0022 - acc: 0.6245 - val_loss: 0.9479 - val_acc: 0.6487\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67252\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9623 - acc: 0.6405 - val_loss: 1.0814 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67252\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9514 - acc: 0.6305 - val_loss: 0.8567 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67252\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9340 - acc: 0.6450 - val_loss: 0.9314 - val_acc: 0.6750\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.67252 to 0.67503, saving model to best_weighted_vgg_multi_model_3.h5\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 86s 855ms/step - loss: 0.9651 - acc: 0.6275 - val_loss: 1.4362 - val_acc: 0.6462\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.67503\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9426 - acc: 0.6400 - val_loss: 1.0259 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.67503\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9467 - acc: 0.6340 - val_loss: 0.9283 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.67503\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9505 - acc: 0.6365 - val_loss: 0.9939 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.67503\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9514 - acc: 0.6295 - val_loss: 1.0403 - val_acc: 0.6587\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.67503\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9232 - acc: 0.6440 - val_loss: 1.0544 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.67503\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9649 - acc: 0.6245 - val_loss: 0.7455 - val_acc: 0.6750\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.67503\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9132 - acc: 0.6605 - val_loss: 0.9845 - val_acc: 0.6424\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.67503\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9618 - acc: 0.6275 - val_loss: 0.8945 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.67503\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9561 - acc: 0.6275 - val_loss: 0.9501 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.67503\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9442 - acc: 0.6415 - val_loss: 1.0323 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.67503\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9419 - acc: 0.6310 - val_loss: 0.6404 - val_acc: 0.6612\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.67503\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9550 - acc: 0.6380 - val_loss: 0.9264 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.67503\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9401 - acc: 0.6440 - val_loss: 1.2516 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.67503\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9471 - acc: 0.6330 - val_loss: 0.9577 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.67503\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9281 - acc: 0.6380 - val_loss: 0.9422 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.67503\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9522 - acc: 0.6335 - val_loss: 0.9414 - val_acc: 0.6537\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.67503\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9536 - acc: 0.6355 - val_loss: 0.9327 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.67503 to 0.68130, saving model to best_weighted_vgg_multi_model_3.h5\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9413 - acc: 0.6375 - val_loss: 0.7853 - val_acc: 0.6412\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.68130\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.9315 - acc: 0.6410 - val_loss: 0.8420 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.68130\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9611 - acc: 0.6315 - val_loss: 0.8470 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.68130\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 0.9257 - acc: 0.6500 - val_loss: 0.8307 - val_acc: 0.6499\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.68130\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 86s 855ms/step - loss: 0.9596 - acc: 0.6205 - val_loss: 0.7871 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.68130\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9598 - acc: 0.6325 - val_loss: 0.9766 - val_acc: 0.6688\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.68130\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9352 - acc: 0.6415 - val_loss: 0.7986 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.68130\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9508 - acc: 0.6340 - val_loss: 1.0865 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.68130\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9262 - acc: 0.6500 - val_loss: 1.2612 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.68130\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9608 - acc: 0.6250 - val_loss: 0.7949 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.68130\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9462 - acc: 0.6315 - val_loss: 0.7907 - val_acc: 0.6537\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.68130\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 86s 855ms/step - loss: 0.9333 - acc: 0.6455 - val_loss: 0.8474 - val_acc: 0.6550\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.68130\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9480 - acc: 0.6340 - val_loss: 0.8949 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.68130\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9518 - acc: 0.6360 - val_loss: 0.8456 - val_acc: 0.6775\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.68130\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9481 - acc: 0.6290 - val_loss: 0.6402 - val_acc: 0.6537\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.68130\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9392 - acc: 0.6440 - val_loss: 1.0759 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.68130\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 86s 855ms/step - loss: 0.9405 - acc: 0.6410 - val_loss: 0.7832 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.68130\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9468 - acc: 0.6330 - val_loss: 0.6838 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.68130\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9418 - acc: 0.6380 - val_loss: 1.2849 - val_acc: 0.6487\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.68130\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9486 - acc: 0.6345 - val_loss: 1.0935 - val_acc: 0.6675\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.68130\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9619 - acc: 0.6340 - val_loss: 0.7854 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.68130\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 86s 855ms/step - loss: 0.9278 - acc: 0.6390 - val_loss: 0.7836 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.68130\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 86s 855ms/step - loss: 0.9222 - acc: 0.6500 - val_loss: 0.6367 - val_acc: 0.6725\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.68130\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9726 - acc: 0.6230 - val_loss: 1.0427 - val_acc: 0.6587\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.68130\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9497 - acc: 0.6320 - val_loss: 0.7863 - val_acc: 0.6524\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.68130\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9435 - acc: 0.6360 - val_loss: 0.6889 - val_acc: 0.6775\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.68130\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9373 - acc: 0.6375 - val_loss: 0.7446 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.68130\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9542 - acc: 0.6345 - val_loss: 0.8316 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.68130\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9430 - acc: 0.6350 - val_loss: 0.8429 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.68130\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 0.9473 - acc: 0.6340 - val_loss: 0.9056 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.68130\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.9409 - acc: 0.6390 - val_loss: 0.7940 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.68130\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9441 - acc: 0.6375 - val_loss: 0.8486 - val_acc: 0.6487\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.68130\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.9520 - acc: 0.6410 - val_loss: 0.6922 - val_acc: 0.6838\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.68130 to 0.68381, saving model to best_weighted_vgg_multi_model_3.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8e6967e8384b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     callbacks=[es,mc])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    717\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'best_weighted_vgg_multi_model_3.h5', errno = 5, error message = 'Input/output error', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaT2FVb5FLHK",
        "outputId": "832e6b5b-9871-49be-9c5b-1ef0b9bd3c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "weighted_model_json = weighted_model.to_json()\n",
        "with open(\"weighted_model.json\", \"w\") as json_file:\n",
        "    json_file.write(weighted_model_json)\n",
        "# serialize weights to HDF5\n",
        "weighted_model.save(\"resnet_weighted_1.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCm5pFBrFLHN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}