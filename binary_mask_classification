{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "binary_class.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Pr6m7EidEX",
        "outputId": "35b3b172-f7e5-4e21-a48a-0763d3648f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.test.gpu_device_name() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQhQzxG-tk2D",
        "outputId": "a601efdb-b0f9-4a83-b289-65d4a1e0c890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJo3xfFEtuqj",
        "outputId": "1bf3bba7-63d3-4197-ed97-3a0240378789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/binary\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/binary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3FEUU1iuA9O"
      },
      "source": [
        "#!unzip type_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkoIWuVxhYap"
      },
      "source": [
        "import os,shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TthY2rvfhYaw"
      },
      "source": [
        "from skimage.io import imread, imshow, imsave"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8mJ5kckhYa0"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqAx82c6hYa8"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SreVMUFhYa8"
      },
      "source": [
        "path_to_annotations = '/Users/shruthiravi/Documents/rsi_20/mask_data/annotations/'\n",
        "list_of_annotations = os.listdir(path = path_to_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y1kl78VhYbA"
      },
      "source": [
        "correct_files = []\n",
        "for number in list_of_annotations:\n",
        "    if '.json' in number:\n",
        "        correct_files.append(number)\n",
        "    else:\n",
        "        print(number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEKrXyBJhYbD"
      },
      "source": [
        "all_annotations = {}\n",
        "for fname in correct_files:\n",
        "    # open file     \n",
        "    with open(os.path.join(path_to_annotations, fname)) as f:\n",
        "        # load file & get into dict\n",
        "        data = json.load(f)    \n",
        "    # extract value of the FileName key\n",
        "    fileNameKey = data['FileName']\n",
        "    # initialize empty list\n",
        "    annotations_list = []\n",
        "    # for each element in annotations\n",
        "    for element in data['Annotations']:\n",
        "        # extract bounding_box\n",
        "        bounding_box = element['BoundingBox']\n",
        "        # extract class_name\n",
        "        class_name = element['classname']\n",
        "        # put them into a tuple \n",
        "        final_annotation = (bounding_box, class_name)\n",
        "        # put the tuple into list\n",
        "        annotations_list.append(final_annotation)\n",
        "    # list becomes value of key\n",
        "    all_annotations[fileNameKey] = annotations_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGm6tEhhYbY"
      },
      "source": [
        "print(all_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozAsVHThYbc"
      },
      "source": [
        "classes = []\n",
        "for key in all_annotations:\n",
        "    for element in all_annotations[key]:\n",
        "        classes.append(element[1])\n",
        "set_of_classes = set(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43eTiuDLhYbl"
      },
      "source": [
        "set([e[1] for k in all_annotations.keys() for e in all_annotations[k] ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwWuyIlJhYbo"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FShk_CvhYbt"
      },
      "source": [
        "Counter(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXdsKg34hYbv"
      },
      "source": [
        "base_dir = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imABXEe1hYby"
      },
      "source": [
        "splits = [x for x in os.listdir(base_dir) if x != '.DS_Store']\n",
        "splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2AhK-TJhYb9"
      },
      "source": [
        "folds = ['train', 'test', 'valid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zTt0hTzhYcC"
      },
      "source": [
        "mask_types = ['mask_surgical','scarf_bandana', 'mask_colorful','face_shield']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f643U5qPhYcF"
      },
      "source": [
        "for fold in folds:\n",
        "     os.mkdir(os.path.join(base_dir, fold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXXOd7AfhYcH"
      },
      "source": [
        "for fold in folds:\n",
        "    for folder in mask_types:\n",
        "        splits_dir = os.path.join(base_dir, fold)\n",
        "        os.mkdir(os.path.join(splits_dir, folder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OevJr9KdhYcJ"
      },
      "source": [
        "def save_photos(tuple_of_info, path_to_save, occurence, img_path='/Users/shruthiravi/Documents/rsi_20/mask_data/images'):\n",
        "    '''this function takes in a tuple'''\n",
        "    name, label, bb = tuple_of_info\n",
        "    final_path = os.path.join(path_to_save, label)\n",
        "    image = imread(os.path.join(img_path, name))\n",
        "    [tl_x, tl_y, br_x, br_y] = bb\n",
        "    cropped = image[tl_y:br_y, tl_x:br_x, :] \n",
        "    name_pieces = name.split('.')\n",
        "    new_name = name_pieces[0] + f\"_{occurence}.\" + name_pieces[1]\n",
        "    further_path = os.path.join(path_to_save, label)\n",
        "    imsave(os.path.join(further_path, new_name), cropped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ1cK1XRhYca"
      },
      "source": [
        "#current_img_name = ''\n",
        "needed_labels = ['face_with_mask', 'face_other_covering','face_with_mask_incorrect']\n",
        "mask_labels = ['mask_surgical','scarf_bandana', 'mask_colorful','face_shield']\n",
        "cropped_annotations = [] # list of three-tuples, each containing (img_name, label, bb)\n",
        "#test = []\n",
        "#train = []\n",
        "#valid = []\n",
        "# for annotation in annotations_list\n",
        "for current_img_name in all_annotations.keys():\n",
        "    for i, annotation in enumerate(all_annotations[current_img_name]):\n",
        "        # extract bounding box\n",
        "        bb = annotation[0]\n",
        "        # crop to bounding box\n",
        "        # extract classname\n",
        "        label = annotation[1]\n",
        "        # crop to bounding box    \n",
        "        if label in needed_labels: \n",
        "            [tl_x, tl_y, br_x, br_y] = bb\n",
        "            if (br_x-tl_x) > 0 and (br_y-tl_y) >0:\n",
        "                for val_label in all_annotations[current_img_name][i+1:]:\n",
        "                    mask_type = val_label[1]\n",
        "                    if mask_type in mask_labels:\n",
        "                        specific_bb = val_label[0]\n",
        "                        [tl_c_x, tl_c_y,br_c_x,br_c_y] = specific_bb\n",
        "                        if tl_c_x > tl_x & tl_c_y > tl_y & br_c_x < br_x & br_c_y < br_y:\n",
        "                            fixed = (current_img_name, mask_type, bb)\n",
        "                            cropped_annotations.append(fixed) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raeuPKH9hYcf"
      },
      "source": [
        "#save_photos(train[1301],'/Users/shruthiravi/Documents/rsi_20/mask_type_classification/train', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOsQ5yQFhYcs"
      },
      "source": [
        "# randomly shuffle the list \n",
        "random.shuffle(cropped_annotations)\n",
        "# determine which split\n",
        "total_size = len(cropped_annotations)\n",
        "perc_train = 0.7\n",
        "perc_test = 0.15\n",
        "perc_valid = 0.15\n",
        "\n",
        "train = cropped_annotations[0:int(perc_train*total_size)]\n",
        "test = cropped_annotations[int(perc_train*total_size):int((perc_train+perc_test)*total_size)]\n",
        "valid = cropped_annotations[int((perc_train+perc_test)*total_size):]\n",
        "fold_dict = {'train': train, 'test': test, 'valid': valid}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZEStAvthYcv"
      },
      "source": [
        "Counter([b[1] for b in train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "falRa6Z0hYcx"
      },
      "source": [
        "dest_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/'\n",
        "# train_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/train'\n",
        "# test_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/test'\n",
        "# valid_path = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/valid'\n",
        "num_occ = {}\n",
        "\n",
        "for fold in fold_dict:\n",
        "    for example in fold_dict[fold]:\n",
        "        if example[0] in num_occ:\n",
        "            num_occ[example[0]] += 1\n",
        "        else:\n",
        "            num_occ[example[0]] = 0\n",
        "        save_photos(example, os.path.join(dest_path, fold), num_occ[example[0]])\n",
        "        print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUKSdB4YhYcz"
      },
      "source": [
        "def print_img(fname):\n",
        "    test_image = imread('/Users/shruthiravi/Documents/rsi_20/mask_data/images/%s' % fname)\n",
        "    test_annotations = all_annotations[fname]\n",
        "    y, x, c = test_image.shape\n",
        "    colors = ['red', 'green', 'blue', 'pink', 'black']\n",
        "    for i, ann in enumerate(test_annotations):\n",
        "        [tl_x, tl_y, br_x, br_y] = ann[0]\n",
        "        color = colors[i%len(colors)]\n",
        "        plt.plot(range(tl_x, br_x),[tl_y for _ in range(tl_x, br_x)],  c=color, label = ann[1])\n",
        "        plt.plot([tl_x for _ in range(tl_y, br_y)],range(tl_y, br_y),  c=color)\n",
        "        plt.plot(range(tl_x, br_x), [br_y for _ in range(tl_x, br_x)], c=color)\n",
        "        plt.plot([br_x for _ in range(tl_y, br_y)], range(tl_y, br_y), c=color)\n",
        "        #plt.legend()\n",
        "        imshow(test_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T_7n1cnu4ns",
        "outputId": "62205ba8-7949-4f57-9ed8-aab141626552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls {train_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My': No such file or directory\n",
            "ls: cannot access 'Drive/mask_type_class/updated/train/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8nmSDggwusT",
        "outputId": "679eefd4-6697-49f6-c113-fe582f04454c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls {test_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mask_colorful  mask_surgical  respirator  scarf_bandana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_KGdIipwx1l",
        "outputId": "6125f787-84b6-4e7a-b3bb-a6363055d29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls {val_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cloth  respirator  scarf_bandana  surgical\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMWLPS1jhYdQ"
      },
      "source": [
        "# Actual Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zfzbeJvuVac"
      },
      "source": [
        "base_path = r\"\"\"/content/drive/My Drive/binary/\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdY_hT9DhYdE"
      },
      "source": [
        "train_dir = base_path + \"train/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJDqs2FmhYdO"
      },
      "source": [
        "val_dir = base_path + \"valid/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2PfPnR7hYdI"
      },
      "source": [
        "test_dir = base_path + \"test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x21Ng8bqhYdR",
        "outputId": "a9bb471e-80ed-4111-b450-6957f39ace7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gb9Z24hYdT"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzEwXCOMhYdV",
        "outputId": "0b883dbb-02b9-42b7-ef97-dc1f3e94eff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4538 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2eF16P0hYd1",
        "outputId": "039aea5e-bc96-4bd8-e0cd-9cc649a2c4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 999 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FQjGsPyhYd8",
        "outputId": "07ac4296-35ef-4b91-abc4-1b0f581fda7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (20, 150, 150, 3)\n",
            "labels batch shape: (20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NO0686UhYeC"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mxoHR8ZhYeC"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n",
        "                       input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M0eF0fKhYeF",
        "outputId": "0c3a80ac-da7e-4aea-d24b-7efe60864522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNl4CmerhYeH"
      },
      "source": [
        "# Compile "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhyR4RwNhYeI"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbKdHrpahYeZ"
      },
      "source": [
        "# Fit using Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQIEmqLDhYeZ",
        "outputId": "d6fa60b6-36fc-443e-c5bb-ea37871c32f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=40,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - 744s 7s/step - loss: 0.3235 - acc: 0.8829 - val_loss: 0.2397 - val_acc: 0.9350\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - 666s 7s/step - loss: 0.1961 - acc: 0.9280 - val_loss: 0.1391 - val_acc: 0.9325\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 133s 1s/step - loss: 0.1589 - acc: 0.9510 - val_loss: 0.0757 - val_acc: 0.9649\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1302 - acc: 0.9510 - val_loss: 0.1292 - val_acc: 0.9500\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1228 - acc: 0.9580 - val_loss: 0.0644 - val_acc: 0.9599\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1176 - acc: 0.9595 - val_loss: 0.0339 - val_acc: 0.9800\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0797 - acc: 0.9715 - val_loss: 0.0236 - val_acc: 0.9700\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0861 - acc: 0.9680 - val_loss: 0.0615 - val_acc: 0.9799\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0906 - acc: 0.9685 - val_loss: 0.0416 - val_acc: 0.9850\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0746 - acc: 0.9735 - val_loss: 0.1151 - val_acc: 0.9649\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0736 - acc: 0.9735 - val_loss: 0.0093 - val_acc: 0.9875\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0552 - acc: 0.9785 - val_loss: 0.0898 - val_acc: 0.9750\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0702 - acc: 0.9750 - val_loss: 0.0640 - val_acc: 0.9674\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0655 - acc: 0.9770 - val_loss: 0.0297 - val_acc: 0.9675\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0442 - acc: 0.9840 - val_loss: 0.0327 - val_acc: 0.9900\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0627 - acc: 0.9795 - val_loss: 0.1375 - val_acc: 0.9725\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0430 - acc: 0.9875 - val_loss: 4.6190e-04 - val_acc: 0.9900\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0414 - acc: 0.9850 - val_loss: 0.0060 - val_acc: 0.9825\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0514 - acc: 0.9805 - val_loss: 0.0048 - val_acc: 0.9750\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0383 - acc: 0.9865 - val_loss: 0.2895 - val_acc: 0.9749\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 0.0469 - val_acc: 0.9775\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0345 - acc: 0.9880 - val_loss: 0.0150 - val_acc: 0.9875\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0262 - val_acc: 0.9875\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0374 - acc: 0.9880 - val_loss: 0.0036 - val_acc: 0.9900\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.0012 - val_acc: 0.9925\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0265 - acc: 0.9905 - val_loss: 0.0028 - val_acc: 0.9825\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0327 - acc: 0.9890 - val_loss: 0.0102 - val_acc: 0.9850\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.0232 - acc: 0.9920 - val_loss: 7.2796e-04 - val_acc: 0.9925\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0213 - acc: 0.9955 - val_loss: 2.2590e-04 - val_acc: 0.9875\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.0178 - acc: 0.9920 - val_loss: 0.0061 - val_acc: 0.9900\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0289 - acc: 0.9880 - val_loss: 0.1773 - val_acc: 0.9775\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0170 - acc: 0.9925 - val_loss: 1.4946e-04 - val_acc: 0.9875\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0125 - acc: 0.9945 - val_loss: 0.0012 - val_acc: 0.9474\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0189 - acc: 0.9930 - val_loss: 0.1339 - val_acc: 0.9925\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0139 - acc: 0.9950 - val_loss: 5.7268e-04 - val_acc: 0.9975\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.0013 - val_acc: 0.9900\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 3.8853e-05 - val_acc: 0.9950\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0119 - acc: 0.9955 - val_loss: 1.4498e-05 - val_acc: 0.9774\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.0098 - acc: 0.9955 - val_loss: 0.0035 - val_acc: 0.9875\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0107 - acc: 0.9960 - val_loss: 0.2894 - val_acc: 0.9699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uZ0LjSThYed"
      },
      "source": [
        "# Save The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoZm2ZkGhYee",
        "outputId": "4579d819-5993-4c2f-8e1d-78115f80972c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save(\".h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRDg8cwihYeg"
      },
      "source": [
        "# Test it Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX6v3LXdhYeg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "model = load_model('my_model_1.h5')\n",
        "\n",
        "# Load model\n",
        "#model = load_model('model.json')\n",
        "\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "#test_generator = test_datagen.flow_from_directory(\n",
        "#        test_dir,\n",
        "#        target_size=(150, 150),\n",
        "#        batch_size=20,\n",
        "#        class_mode='categorical',\n",
        "#        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uaGWX-6hYeo"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=test_dir,\n",
        "    target_size=(28, 28),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqZI7UtnhYep"
      },
      "source": [
        "test_generator.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUl6nrhNhYez"
      },
      "source": [
        "pred=cnn.predict_generator(test_generator,verbose=1,steps=306/batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHwlfEPchYe4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4gN3AVWhYe-"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YTP4LwdhYe-"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9GIxmW7hYfE"
      },
      "source": [
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xKC9iZThYfG"
      },
      "source": [
        "train_face_shield_dir = '/Users/shruthiravi/Documents/rsi_20/mask_type_classification/train/face_shield/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0oOdiwfhYfI"
      },
      "source": [
        "fnames = [os.path.join(train_face_shield_dir, fname) for\n",
        "         fname in os.listdir(train_face_shield_dir)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqeZsZJwhYfK"
      },
      "source": [
        "img_path = fnames[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGNg4HN6hYfQ"
      },
      "source": [
        "img = image.load_img(img_path, target_size=(150,150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AZlEFH0hYfc"
      },
      "source": [
        "x = image.img_to_array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEx0jyAkhYfn"
      },
      "source": [
        "x = x.reshape((1,) + x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxWZ25MQhYf3"
      },
      "source": [
        "i = 0\n",
        "for batch in datagen.flow(x,batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0 :\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYP51E4hYgM"
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4qnJZu0hYgO"
      },
      "source": [
        "# Adding Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIf0YnbLhYgO"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n",
        "                       input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv_5Aq1ghYgS"
      },
      "source": [
        "train_datagen = ImageDataGenerator (\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=-.2,\n",
        "    horizontal_flip=True,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_0BjU4shYgT"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_RKFm8qhYgV",
        "outputId": "f870e3c0-f613-40d6-94da-11acd38eab84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4538 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AsVyMlvhYgY",
        "outputId": "27852100-8a7d-4a1b-dabc-a2b364917c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 999 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKv5ai2HPnb9",
        "outputId": "df648b2c-fb47-4f01-d63f-f85450007392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CKOBPz7hYga",
        "outputId": "7f2be143-17b6-4b09-c813-51065df83d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=40,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - 770s 8s/step - loss: 0.3600 - acc: 0.8955 - val_loss: 0.3241 - val_acc: 0.9050\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - 589s 6s/step - loss: 0.2682 - acc: 0.8959 - val_loss: 0.1417 - val_acc: 0.9416\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 119s 1s/step - loss: 0.2399 - acc: 0.9150 - val_loss: 0.1639 - val_acc: 0.9500\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.2003 - acc: 0.9230 - val_loss: 0.1172 - val_acc: 0.9482\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 21s 205ms/step - loss: 0.2001 - acc: 0.9274 - val_loss: 0.1240 - val_acc: 0.9249\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.1961 - acc: 0.9244 - val_loss: 0.0659 - val_acc: 0.9633\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.1867 - acc: 0.9230 - val_loss: 0.0578 - val_acc: 0.9666\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.1559 - acc: 0.9350 - val_loss: 0.0253 - val_acc: 0.9683\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.1594 - acc: 0.9404 - val_loss: 0.0973 - val_acc: 0.9666\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.1601 - acc: 0.9449 - val_loss: 0.0999 - val_acc: 0.9666\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1505 - acc: 0.9425 - val_loss: 0.0200 - val_acc: 0.9633\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.1476 - acc: 0.9440 - val_loss: 0.1855 - val_acc: 0.9699\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.1583 - acc: 0.9415 - val_loss: 0.0300 - val_acc: 0.9700\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.1392 - acc: 0.9444 - val_loss: 0.0194 - val_acc: 0.9683\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1480 - acc: 0.9474 - val_loss: 0.1024 - val_acc: 0.9733\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - 20s 202ms/step - loss: 0.1560 - acc: 0.9400 - val_loss: 0.0603 - val_acc: 0.9800\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.1343 - acc: 0.9460 - val_loss: 0.0571 - val_acc: 0.9716\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - 20s 202ms/step - loss: 0.1319 - acc: 0.9479 - val_loss: 0.0556 - val_acc: 0.9633\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.1396 - acc: 0.9510 - val_loss: 0.1346 - val_acc: 0.9766\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.1164 - acc: 0.9510 - val_loss: 0.0884 - val_acc: 0.9666\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1464 - acc: 0.9465 - val_loss: 0.1181 - val_acc: 0.9650\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.1342 - acc: 0.9460 - val_loss: 0.2180 - val_acc: 0.9583\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.1279 - acc: 0.9514 - val_loss: 0.3007 - val_acc: 0.9517\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1243 - acc: 0.9550 - val_loss: 0.0320 - val_acc: 0.9533\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.1185 - acc: 0.9560 - val_loss: 0.1959 - val_acc: 0.9699\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.1079 - acc: 0.9545 - val_loss: 0.0073 - val_acc: 0.9600\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1189 - acc: 0.9490 - val_loss: 0.1685 - val_acc: 0.9633\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.1145 - acc: 0.9615 - val_loss: 0.0094 - val_acc: 0.9717\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.1277 - acc: 0.9455 - val_loss: 0.0644 - val_acc: 0.9633\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.1134 - acc: 0.9544 - val_loss: 0.0880 - val_acc: 0.9766\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.1123 - acc: 0.9625 - val_loss: 0.1833 - val_acc: 0.9700\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.1148 - acc: 0.9560 - val_loss: 0.1264 - val_acc: 0.9633\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.1159 - acc: 0.9535 - val_loss: 0.0593 - val_acc: 0.9717\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.1237 - acc: 0.9530 - val_loss: 0.0069 - val_acc: 0.9766\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.1112 - acc: 0.9605 - val_loss: 0.0511 - val_acc: 0.9466\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.1143 - acc: 0.9570 - val_loss: 0.0040 - val_acc: 0.9650\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.1084 - acc: 0.9555 - val_loss: 0.1891 - val_acc: 0.9733\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.1241 - acc: 0.9585 - val_loss: 0.0339 - val_acc: 0.9750\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.1055 - acc: 0.9580 - val_loss: 0.0298 - val_acc: 0.9716\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.1036 - acc: 0.9605 - val_loss: 0.0020 - val_acc: 0.9616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPFkxY0hYgd",
        "outputId": "62df83e0-6993-4d7b-a8ca-4a9767c901c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"dropout_binary_7_21.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save(\"dropout_binary_7_21.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3RbeW9hYgf"
      },
      "source": [
        "# NEW DATA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlL3WnsbhYgg"
      },
      "source": [
        "train_dir = '/Users/shruthiravi/Documents/rsi_20/combined/train/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyGwFpd5hYgh"
      },
      "source": [
        "test_dir = '/Users/shruthiravi/Documents/rsi_20/combined/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvqQs0kkhYgk"
      },
      "source": [
        "val_dir = '/Users/shruthiravi/Documents/rsi_20/combined/valid/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWGyN0dmhYgn"
      },
      "source": [
        "# Actual Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyT2axkFhYgq"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNsCtByOhYhA"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb4_dlIahYhB",
        "outputId": "3f72ed12-dba8-4eaa-c51f-d09fab966fd3"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4100 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejgNZDhhYhD",
        "outputId": "6741a3cc-100d-49d3-8561-df2de136b17d"
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 897 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhmbFYamhYhG"
      },
      "source": [
        "i = 0\n",
        "for batch in validation_generator.:\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0 :\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci1jmpSihYhS",
        "outputId": "a3f0f0c5-8264-46b6-e33d-da61a4effad6"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (20, 150, 150, 3)\n",
            "labels batch shape: (20, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecN3hdB-hYhY"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC048AudhYhY"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',\n",
        "                       input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(4,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsw1Bqm5hYha",
        "outputId": "d8ff0afb-f7ad-499f-8e9c-9e3044cfe4ac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,454,660\n",
            "Trainable params: 3,454,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRKk3x9WhYhb"
      },
      "source": [
        "# Compile "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH1M3fsLhYhc"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-FnS6FihYhd",
        "outputId": "2b7d3aad-3212-48fe-dd9f-c39462101a5d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,454,660\n",
            "Trainable params: 3,454,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYZTj2t4hYhj"
      },
      "source": [
        "# Fit using Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4n2LWznhYhk",
        "outputId": "09c71ce9-d24e-4f6e-fd2e-146f5effee69"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochst=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-f0160fe33617>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 52s 522ms/step - loss: 0.3875 - acc: 0.6795 - val_loss: 0.3189 - val_acc: 0.7700\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 54s 543ms/step - loss: 0.3427 - acc: 0.7400 - val_loss: 0.3323 - val_acc: 0.7550\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.3359 - acc: 0.7455 - val_loss: 0.3179 - val_acc: 0.7500\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 51s 508ms/step - loss: 0.3251 - acc: 0.7535 - val_loss: 0.3111 - val_acc: 0.7700\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 51s 510ms/step - loss: 0.3097 - acc: 0.7530 - val_loss: 0.2868 - val_acc: 0.7850\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.2990 - acc: 0.7710 - val_loss: 0.3039 - val_acc: 0.7700\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 0.3067 - acc: 0.7490 - val_loss: 0.3534 - val_acc: 0.7100\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 51s 509ms/step - loss: 0.2959 - acc: 0.7615 - val_loss: 0.2839 - val_acc: 0.7850\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 52s 519ms/step - loss: 0.2769 - acc: 0.7750 - val_loss: 0.2733 - val_acc: 0.7925\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.2735 - acc: 0.7905 - val_loss: 0.2850 - val_acc: 0.7750\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 52s 517ms/step - loss: 0.2761 - acc: 0.7765 - val_loss: 0.2845 - val_acc: 0.7850\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 0.2666 - acc: 0.7900 - val_loss: 0.2796 - val_acc: 0.7925\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 55s 555ms/step - loss: 0.2590 - acc: 0.7925 - val_loss: 0.2501 - val_acc: 0.8150\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 419s 4s/step - loss: 0.2381 - acc: 0.8120 - val_loss: 0.2915 - val_acc: 0.7650\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 63s 632ms/step - loss: 0.2457 - acc: 0.8100 - val_loss: 0.2806 - val_acc: 0.7925\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 0.2314 - acc: 0.8185 - val_loss: 0.2621 - val_acc: 0.8050\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 50s 505ms/step - loss: 0.2289 - acc: 0.8220 - val_loss: 0.2537 - val_acc: 0.8250\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 51s 512ms/step - loss: 0.2153 - acc: 0.8350 - val_loss: 0.2520 - val_acc: 0.8125\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 207s 2s/step - loss: 0.2133 - acc: 0.8370 - val_loss: 0.2837 - val_acc: 0.7900\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 54s 543ms/step - loss: 0.2117 - acc: 0.8375 - val_loss: 0.2640 - val_acc: 0.7975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JKz14YthYhl"
      },
      "source": [
        "# Load the Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztZOKqcDhYhm"
      },
      "source": [
        "# example of loading the resnet50 model\n",
        "from keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHUOxe7j0RgY"
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HadXUblf0iQl"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53QeemGnzKcJ"
      },
      "source": [
        "#help(ResNet50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCp6YocThYho",
        "outputId": "bac6c674-1bf4-42cd-d5ae-5c72d7215039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# load model\n",
        "resnet_model = ResNet50(\n",
        "                classes = 2,\n",
        "                pooling = 'max',\n",
        "                weights = 'imagenet',\n",
        "                include_top = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebnfNaHIz7Nr"
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = resnet_model.output\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(1, activation='sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s3ax46uhYhq",
        "outputId": "ecc6f761-bb6d-4291-b854-14928ca2e395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# summarize the model\n",
        "resnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 2048)         0           activation_49[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a6NkDlQmxJ5"
      },
      "source": [
        "binary_weighted_model = Model(inputs=resnet_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMLuiNYXs0Ga",
        "outputId": "7059a688-9329-44cb-b5c2-5356c25bb865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "binary_weighted_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          1049088     global_max_pooling2d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            513         dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,637,313\n",
            "Trainable params: 24,584,193\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpAZTwMohYht"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "binary_weighted_model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvIJST0YMIaY"
      },
      "source": [
        "cb = Callback()\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = ModelCheckpoint('best_weighted_binary_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7mi1bPKPTZO"
      },
      "source": [
        "my_callbacks = [es, mc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giDXvzC9hYic",
        "outputId": "47e912fa-a946-4145-ad49-ddabf96694a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = binary_weighted_model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=40,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=40,\n",
        "    callb``acks=my_callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - 77s 774ms/step - loss: 0.2183 - acc: 0.9680 - val_loss: 2.9285 - val_acc: 0.8988\n",
            "Epoch 2/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0693 - acc: 0.9860 - val_loss: 0.6610 - val_acc: 0.5482\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0599 - acc: 0.9900 - val_loss: 1.2485 - val_acc: 0.9086\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0543 - acc: 0.9905 - val_loss: 0.0230 - val_acc: 0.8786\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0407 - acc: 0.9900 - val_loss: 5.4189 - val_acc: 0.9024\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0117 - acc: 0.9950 - val_loss: 0.5615 - val_acc: 0.9000\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0260 - acc: 0.9975 - val_loss: 1.1187e-04 - val_acc: 0.9186\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0181 - acc: 0.9955 - val_loss: 0.3071 - val_acc: 0.9612\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0249 - acc: 0.9955 - val_loss: 0.0027 - val_acc: 0.9875\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0151 - acc: 0.9975 - val_loss: 1.9866e-07 - val_acc: 0.9950\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0163 - acc: 0.9975 - val_loss: 2.4055e-07 - val_acc: 0.9950\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0322 - acc: 0.9945 - val_loss: 5.4354e-07 - val_acc: 0.9987\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.3911 - val_acc: 0.9962\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 2.5651e-08 - val_acc: 0.9912\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0175 - acc: 0.9965 - val_loss: 0.0644 - val_acc: 0.9975\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0244 - acc: 0.9960 - val_loss: 1.4410e-06 - val_acc: 0.9962\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - 59s 589ms/step - loss: 0.0167 - acc: 0.9980 - val_loss: 1.4992 - val_acc: 0.9962\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0159 - acc: 0.9965 - val_loss: 2.8549e-12 - val_acc: 0.9950\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 2.3890e-09 - val_acc: 0.9962\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0094 - acc: 0.9965 - val_loss: 3.0766e-10 - val_acc: 0.9912\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0215 - acc: 0.9970 - val_loss: 2.7615e-04 - val_acc: 0.9962\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.0153 - acc: 0.9970 - val_loss: 0.0011 - val_acc: 0.9987\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 59s 589ms/step - loss: 0.0330 - acc: 0.9965 - val_loss: 1.2635e-12 - val_acc: 0.9987\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.0152 - acc: 0.9970 - val_loss: 1.1344e-12 - val_acc: 0.9937\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.0137 - acc: 0.9980 - val_loss: 3.6808e-11 - val_acc: 0.9962\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 59s 589ms/step - loss: 0.0152 - acc: 0.9980 - val_loss: 1.5828e-22 - val_acc: 0.9975\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.0048 - acc: 0.9980 - val_loss: 1.1373e-06 - val_acc: 0.9925\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.0220 - acc: 0.9970 - val_loss: 1.0660e-13 - val_acc: 0.9950\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 59s 589ms/step - loss: 0.0121 - acc: 0.9970 - val_loss: 2.2168e-08 - val_acc: 0.9975\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 2.7810e-24 - val_acc: 0.9950\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 59s 594ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 8.0756e-10 - val_acc: 0.9975\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0210 - acc: 0.9975 - val_loss: 9.6401e-07 - val_acc: 1.0000\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 1.4613e-14 - val_acc: 0.9912\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 3.7727e-07 - val_acc: 0.9962\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0012 - acc: 0.9990 - val_loss: 2.3693e-09 - val_acc: 0.9987\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0082 - acc: 0.9990 - val_loss: 1.6766e-11 - val_acc: 0.9987\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 9.2390e-14 - val_acc: 0.9950\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 59s 589ms/step - loss: 0.0169 - acc: 0.9980 - val_loss: 6.0368e-13 - val_acc: 0.9987\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 59s 587ms/step - loss: 0.0261 - acc: 0.9970 - val_loss: 1.9989e-18 - val_acc: 0.9975\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 59s 587ms/step - loss: 0.0070 - acc: 0.9990 - val_loss: 4.6794e-11 - val_acc: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDwmyibdXWi7",
        "outputId": "cf1a9235-edaa-4019-f1fe-bec8433b615a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "binary_weighted_model_json = binary_weighted_model.to_json()\n",
        "with open(\"binary_weighted_model_7_21.json\", \"w\") as json_file:\n",
        "    json_file.write(binary_weighted_model_json)\n",
        "# serialize weights to HDF5\n",
        "binary_weighted_model.save(\"binary_weighted_7_21.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnqHNj3imYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymplJXydKG1X"
      },
      "source": [
        "VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODIPjpnFHKb"
      },
      "source": [
        "# VGG19\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldq-20nhFLGq"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma2qDvIvFLGv"
      },
      "source": [
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW-XQUHFFLGy"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVpzWOmWFLG3",
        "outputId": "5619350d-5c1e-4830-8438-c89a5c8e83c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# load model\n",
        "vgg_model = VGG16()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 12s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KCGewJqFLG5"
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = vgg_model.output\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(1, activation='sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTkB8XaCFLG-",
        "outputId": "afe72e86-57e2-45bd-bfe8-c2495660439c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# summarize the model\n",
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQp-skVFLHA"
      },
      "source": [
        "wvgg_model = Model(inputs=vgg_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXXjDyM0FLHC",
        "outputId": "78b27bd8-2c97-4e09-9dbc-4e61c00952c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wvgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               512512    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 138,870,569\n",
            "Trainable params: 138,870,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_0erPq8FLHE"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "wvgg_model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPAueRSOFLHG"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint('best_weighted_vgg_binary_model_3.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yJNHAQNFLHI",
        "outputId": "6a306aff-482d-409c-b706-7503955835e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = wvgg_model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=1000,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=40,\n",
        "    callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 943s 9s/step - loss: 0.6094 - acc: 0.8799 - val_loss: 0.5679 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.89750, saving model to best_weighted_vgg_binary_model_3.h5\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 637s 6s/step - loss: 0.4986 - acc: 0.9030 - val_loss: 0.4579 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.89750\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 200s 2s/step - loss: 0.4295 - acc: 0.8949 - val_loss: 0.2838 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.89750 to 0.90363, saving model to best_weighted_vgg_binary_model_3.h5\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3874 - acc: 0.8900 - val_loss: 0.2852 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.90363\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3539 - acc: 0.8945 - val_loss: 0.4364 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.90363\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3362 - acc: 0.8974 - val_loss: 0.2296 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.90363 to 0.90625, saving model to best_weighted_vgg_binary_model_3.h5\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.3369 - acc: 0.8950 - val_loss: 0.2229 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.90625\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3267 - acc: 0.8995 - val_loss: 0.3252 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.90625\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3511 - acc: 0.8879 - val_loss: 0.2204 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.90625\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3364 - acc: 0.8949 - val_loss: 0.3365 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.90625\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3404 - acc: 0.8930 - val_loss: 0.3252 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.90625\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3313 - acc: 0.8974 - val_loss: 0.5422 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.90625\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3542 - acc: 0.8865 - val_loss: 0.4308 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.90625\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3308 - acc: 0.8974 - val_loss: 0.4324 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.90625\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3414 - acc: 0.8925 - val_loss: 0.4485 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.90625\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3329 - acc: 0.8965 - val_loss: 0.4329 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.90625\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.3756 - acc: 0.8764 - val_loss: 0.4295 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.90625\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3170 - acc: 0.9040 - val_loss: 0.5431 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.90625\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3329 - acc: 0.8965 - val_loss: 0.2164 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.90625\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3297 - acc: 0.8979 - val_loss: 0.4517 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.90625\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3375 - acc: 0.8944 - val_loss: 0.2165 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.90625\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3296 - acc: 0.8980 - val_loss: 0.3251 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.90625\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3543 - acc: 0.8865 - val_loss: 0.3254 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.90625 to 0.90738, saving model to best_weighted_vgg_binary_model_3.h5\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3372 - acc: 0.8945 - val_loss: 0.1112 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.90738\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3394 - acc: 0.8934 - val_loss: 0.2237 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.90738\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3536 - acc: 0.8869 - val_loss: 0.4306 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.90738\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3371 - acc: 0.8945 - val_loss: 0.4322 - val_acc: 0.8786\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.90738\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3232 - acc: 0.9010 - val_loss: 0.3251 - val_acc: 0.9199\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.90738 to 0.91990, saving model to best_weighted_vgg_binary_model_3.h5\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3450 - acc: 0.8909 - val_loss: 0.2180 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.91990\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3242 - acc: 0.9005 - val_loss: 0.6818 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.91990\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3416 - acc: 0.8925 - val_loss: 0.3252 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.91990\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.3427 - acc: 0.8919 - val_loss: 0.2183 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.91990\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3133 - acc: 0.9055 - val_loss: 0.3251 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.91990\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3641 - acc: 0.8819 - val_loss: 0.3256 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.91990\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3477 - acc: 0.8894 - val_loss: 0.3366 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.91990\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3318 - acc: 0.8970 - val_loss: 0.2190 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.91990\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3520 - acc: 0.8875 - val_loss: 0.5368 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.91990\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3187 - acc: 0.9030 - val_loss: 0.2150 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.91990\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3579 - acc: 0.8849 - val_loss: 0.2197 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.91990\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3157 - acc: 0.9045 - val_loss: 0.1073 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.91990\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3556 - acc: 0.8859 - val_loss: 0.1135 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.91990\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3383 - acc: 0.8939 - val_loss: 0.3252 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.91990\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3468 - acc: 0.8900 - val_loss: 0.3253 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.91990\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3286 - acc: 0.8985 - val_loss: 0.4323 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.91990\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3361 - acc: 0.8950 - val_loss: 0.3365 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.91990\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3494 - acc: 0.8888 - val_loss: 0.2191 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.91990\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3285 - acc: 0.8985 - val_loss: 0.2159 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.91990\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3469 - acc: 0.8900 - val_loss: 0.3252 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.91990\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3319 - acc: 0.8969 - val_loss: 0.3252 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.91990\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3361 - acc: 0.8950 - val_loss: 0.3365 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.91990\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3318 - acc: 0.8970 - val_loss: 0.2169 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.91990\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3451 - acc: 0.8909 - val_loss: 0.1105 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.91990\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3499 - acc: 0.8885 - val_loss: 0.5364 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.91990\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3297 - acc: 0.8980 - val_loss: 0.5403 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.91990\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3436 - acc: 0.8914 - val_loss: 0.1118 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.91990\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3386 - acc: 0.8939 - val_loss: 0.4327 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.91990\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3264 - acc: 0.8995 - val_loss: 0.3251 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.91990\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3415 - acc: 0.8925 - val_loss: 0.2177 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.91990\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3427 - acc: 0.8919 - val_loss: 0.4322 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.91990\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3510 - acc: 0.8880 - val_loss: 0.6691 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.91990\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3322 - acc: 0.8969 - val_loss: 0.1121 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.91990\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3340 - acc: 0.8960 - val_loss: 0.5390 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.91990\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3308 - acc: 0.8974 - val_loss: 0.6484 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.91990\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3407 - acc: 0.8929 - val_loss: 0.2176 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.91990\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3415 - acc: 0.8925 - val_loss: 0.6747 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.91990\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3510 - acc: 0.8880 - val_loss: 0.2204 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.91990\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3373 - acc: 0.8944 - val_loss: 0.4318 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.91990\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3306 - acc: 0.8975 - val_loss: 0.3251 - val_acc: 0.9111\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.91990\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3340 - acc: 0.8960 - val_loss: 0.4338 - val_acc: 0.8836\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.91990\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3374 - acc: 0.8944 - val_loss: 0.2227 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.91990\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3563 - acc: 0.8855 - val_loss: 0.3255 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.91990\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3190 - acc: 0.9029 - val_loss: 0.3251 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.91990\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3415 - acc: 0.8925 - val_loss: 0.1112 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.91990\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3340 - acc: 0.8960 - val_loss: 0.2175 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.91990\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3491 - acc: 0.8889 - val_loss: 0.4482 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.91990\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3403 - acc: 0.8930 - val_loss: 0.3254 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.91990\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3353 - acc: 0.8954 - val_loss: 0.5397 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.91990\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3478 - acc: 0.8895 - val_loss: 0.5369 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.91990\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3405 - acc: 0.8929 - val_loss: 0.2190 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.91990\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3373 - acc: 0.8944 - val_loss: 0.3365 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.91990\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3210 - acc: 0.9020 - val_loss: 0.1081 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.91990\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.3426 - acc: 0.8920 - val_loss: 0.4326 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.91990\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3383 - acc: 0.8940 - val_loss: 0.1102 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.91990\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3415 - acc: 0.8924 - val_loss: 0.5410 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.91990\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3306 - acc: 0.8975 - val_loss: 0.9102 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.91990\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3436 - acc: 0.8914 - val_loss: 0.5426 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.91990\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3650 - acc: 0.8815 - val_loss: 0.3255 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.91990\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3214 - acc: 0.9019 - val_loss: 0.3251 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.91990\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3275 - acc: 0.8990 - val_loss: 0.2159 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.91990\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3208 - acc: 0.9020 - val_loss: 0.2205 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.91990\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3708 - acc: 0.8789 - val_loss: 0.2210 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.91990\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3384 - acc: 0.8939 - val_loss: 0.2198 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.91990\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3286 - acc: 0.8985 - val_loss: 0.4329 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.91990\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3386 - acc: 0.8939 - val_loss: 0.4331 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.91990\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3307 - acc: 0.8975 - val_loss: 0.6791 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.91990\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3576 - acc: 0.8849 - val_loss: 0.4308 - val_acc: 0.9050\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.91990\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3211 - acc: 0.9020 - val_loss: 0.2160 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.91990\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3480 - acc: 0.8895 - val_loss: 0.3252 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.91990\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3201 - acc: 0.9024 - val_loss: 0.6548 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.91990\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3588 - acc: 0.8845 - val_loss: 0.3365 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.91990\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3320 - acc: 0.8969 - val_loss: 0.4324 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.91990\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3414 - acc: 0.8925 - val_loss: 0.2192 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.91990\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3275 - acc: 0.8990 - val_loss: 0.2164 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.91990\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3634 - acc: 0.8824 - val_loss: 0.3256 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.91990\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3287 - acc: 0.8985 - val_loss: 0.3365 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.91990\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3350 - acc: 0.8955 - val_loss: 0.1096 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.91990\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3428 - acc: 0.8919 - val_loss: 0.2185 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.91990\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3532 - acc: 0.8869 - val_loss: 0.2209 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.91990\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3178 - acc: 0.9035 - val_loss: 0.2155 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.91990\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3630 - acc: 0.8825 - val_loss: 0.3365 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.91990\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3244 - acc: 0.9005 - val_loss: 0.6493 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.91990\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.3390 - acc: 0.8938 - val_loss: 0.2182 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.91990\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3134 - acc: 0.9055 - val_loss: 0.1055 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.91990\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3621 - acc: 0.8829 - val_loss: 0.2184 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.91990\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3404 - acc: 0.8930 - val_loss: 0.3365 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.91990\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3478 - acc: 0.8895 - val_loss: 0.2200 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.91990\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3307 - acc: 0.8975 - val_loss: 0.1096 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.91990\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3276 - acc: 0.8989 - val_loss: 0.4337 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.91990\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3543 - acc: 0.8865 - val_loss: 0.4310 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.91990\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3406 - acc: 0.8929 - val_loss: 0.4479 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.91990\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3211 - acc: 0.9020 - val_loss: 0.4332 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.91990\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3522 - acc: 0.8875 - val_loss: 0.4315 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.91990\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3223 - acc: 0.9014 - val_loss: 0.3251 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.91990\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3511 - acc: 0.8880 - val_loss: 0.1141 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.91990\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3308 - acc: 0.8974 - val_loss: 0.4497 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.91990\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3556 - acc: 0.8859 - val_loss: 0.4306 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.91990\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.3232 - acc: 0.9010 - val_loss: 0.1081 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.91990\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3425 - acc: 0.8920 - val_loss: 0.4326 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.91990\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3242 - acc: 0.9005 - val_loss: 0.1068 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.91990\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3463 - acc: 0.8903 - val_loss: 0.2233 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.91990\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3584 - acc: 0.8845 - val_loss: 0.5364 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.91990\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3319 - acc: 0.8970 - val_loss: 0.2182 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.91990\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3114 - acc: 0.9064 - val_loss: 0.4348 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.91990\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3564 - acc: 0.8855 - val_loss: 0.1146 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.91990\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3419 - acc: 0.8924 - val_loss: 0.1129 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.91990\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3478 - acc: 0.8895 - val_loss: 0.3254 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.91990\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3382 - acc: 0.8940 - val_loss: 0.2205 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.91990\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3393 - acc: 0.8934 - val_loss: 0.2193 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.91990\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3308 - acc: 0.8975 - val_loss: 0.3252 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.91990\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3275 - acc: 0.8990 - val_loss: 0.3365 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.91990\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3421 - acc: 0.8924 - val_loss: 0.2176 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.91990\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3531 - acc: 0.8870 - val_loss: 0.4312 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.91990\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3289 - acc: 0.8984 - val_loss: 0.4327 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.91990\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3480 - acc: 0.8894 - val_loss: 0.4319 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.91990\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3361 - acc: 0.8950 - val_loss: 0.3365 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.91990\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3159 - acc: 0.9044 - val_loss: 0.2151 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.91990\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.3174 - acc: 0.9035 - val_loss: 0.2131 - val_acc: 0.8836\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.91990\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3592 - acc: 0.8845 - val_loss: 0.4338 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.91990\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3427 - acc: 0.8919 - val_loss: 0.2178 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.91990\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3573 - acc: 0.8850 - val_loss: 0.2269 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.91990\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3343 - acc: 0.8959 - val_loss: 0.3254 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.91990\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3383 - acc: 0.8940 - val_loss: 0.3253 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.91990\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3477 - acc: 0.8895 - val_loss: 0.6404 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.91990\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3268 - acc: 0.8994 - val_loss: 0.3252 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.91990\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3361 - acc: 0.8950 - val_loss: 0.5618 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.91990\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3384 - acc: 0.8939 - val_loss: 0.4322 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.91990\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3382 - acc: 0.8940 - val_loss: 0.5401 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.91990\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3377 - acc: 0.8944 - val_loss: 0.3252 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.91990\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3468 - acc: 0.8900 - val_loss: 0.5384 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.91990\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3382 - acc: 0.8940 - val_loss: 0.3365 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.91990\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3329 - acc: 0.8965 - val_loss: 0.2180 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.91990\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3598 - acc: 0.8838 - val_loss: 0.4293 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.91990\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3246 - acc: 0.9005 - val_loss: 0.1115 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.91990\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3264 - acc: 0.8995 - val_loss: 0.2165 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.91990\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3372 - acc: 0.8945 - val_loss: 0.3366 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.91990\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3464 - acc: 0.8903 - val_loss: 0.1099 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.91990\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.3552 - acc: 0.8860 - val_loss: 0.4310 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.91990\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3275 - acc: 0.8990 - val_loss: 0.1086 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.91990\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3404 - acc: 0.8929 - val_loss: 0.6477 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.91990\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3404 - acc: 0.8930 - val_loss: 0.2239 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.91990\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3361 - acc: 0.8949 - val_loss: 0.5396 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.91990\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3510 - acc: 0.8880 - val_loss: 0.2193 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.91990\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3090 - acc: 0.9075 - val_loss: 0.3251 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.91990\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3439 - acc: 0.8914 - val_loss: 0.2175 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.91990\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3520 - acc: 0.8875 - val_loss: 0.4470 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.91990\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3299 - acc: 0.8979 - val_loss: 0.5396 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.91990\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3425 - acc: 0.8920 - val_loss: 0.4323 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.91990\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3361 - acc: 0.8950 - val_loss: 0.1098 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.91990\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3386 - acc: 0.8939 - val_loss: 0.1122 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.91990\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3435 - acc: 0.8915 - val_loss: 0.3365 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.91990\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3499 - acc: 0.8885 - val_loss: 0.1151 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.91990\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3214 - acc: 0.9019 - val_loss: 0.4336 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.91990\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3385 - acc: 0.8939 - val_loss: 0.3251 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.91990\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3426 - acc: 0.8920 - val_loss: 0.4324 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.91990\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3246 - acc: 0.9004 - val_loss: 0.6812 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.91990\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3480 - acc: 0.8895 - val_loss: 0.2186 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.91990\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.3597 - acc: 0.8839 - val_loss: 0.3255 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.91990\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3276 - acc: 0.8990 - val_loss: 0.2181 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.91990\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3175 - acc: 0.9035 - val_loss: 0.2141 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.91990\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3438 - acc: 0.8915 - val_loss: 0.1092 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.91990\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3533 - acc: 0.8869 - val_loss: 0.2197 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.91990\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3371 - acc: 0.8945 - val_loss: 0.3252 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.91990\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3363 - acc: 0.8949 - val_loss: 0.3252 - val_acc: 0.9074\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.91990\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3266 - acc: 0.8994 - val_loss: 0.5435 - val_acc: 0.8911\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.91990\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3437 - acc: 0.8915 - val_loss: 0.2229 - val_acc: 0.9011\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.91990\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3489 - acc: 0.8890 - val_loss: 0.3253 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.91990\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3429 - acc: 0.8919 - val_loss: 0.2183 - val_acc: 0.8861\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.91990\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3134 - acc: 0.9055 - val_loss: 0.3251 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.91990\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3556 - acc: 0.8860 - val_loss: 0.4319 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.91990\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3416 - acc: 0.8924 - val_loss: 0.3365 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.91990\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3124 - acc: 0.9059 - val_loss: 0.3251 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00201: val_acc did not improve from 0.91990\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3631 - acc: 0.8825 - val_loss: 0.2196 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00202: val_acc did not improve from 0.91990\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3456 - acc: 0.8905 - val_loss: 0.1151 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00203: val_acc did not improve from 0.91990\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3414 - acc: 0.8924 - val_loss: 0.3255 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00204: val_acc did not improve from 0.91990\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3158 - acc: 0.9045 - val_loss: 0.3365 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00205: val_acc did not improve from 0.91990\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.3532 - acc: 0.8870 - val_loss: 0.3254 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00206: val_acc did not improve from 0.91990\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.3374 - acc: 0.8944 - val_loss: 0.3253 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00207: val_acc did not improve from 0.91990\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3531 - acc: 0.8869 - val_loss: 0.2212 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00208: val_acc did not improve from 0.91990\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3201 - acc: 0.9025 - val_loss: 0.5417 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00209: val_acc did not improve from 0.91990\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3165 - acc: 0.9040 - val_loss: 0.2205 - val_acc: 0.9036\n",
            "\n",
            "Epoch 00210: val_acc did not improve from 0.91990\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.3739 - acc: 0.8774 - val_loss: 0.4307 - val_acc: 0.9038\n",
            "\n",
            "Epoch 00211: val_acc did not improve from 0.91990\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.3354 - acc: 0.8954 - val_loss: 0.4327 - val_acc: 0.8836\n",
            "\n",
            "Epoch 00212: val_acc did not improve from 0.91990\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.3382 - acc: 0.8940 - val_loss: 0.1083 - val_acc: 0.9086\n",
            "\n",
            "Epoch 00213: val_acc did not improve from 0.91990\n",
            "Epoch 00213: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaT2FVb5FLHK",
        "outputId": "832e6b5b-9871-49be-9c5b-1ef0b9bd3c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "weighted_model_json = weighted_model.to_json()\n",
        "with open(\"weighted_model.json\", \"w\") as json_file:\n",
        "    json_file.write(weighted_model_json)\n",
        "# serialize weights to HDF5\n",
        "weighted_model.save(\"resnet_weighted_1.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCm5pFBrFLHN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}